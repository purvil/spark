{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/purvil/spark-2.4.3-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Aggregation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = spark.createDataFrame([\n",
    "    (0, \"Purvil Dave\", 0, [100]),\n",
    "    (1, \"Bhavika Joshi\", 1, [500,250,100]),\n",
    "    (2, \"Japan Dave\", 1, [250,100])\n",
    "]).toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graduateProgram = spark.createDataFrame([\n",
    "    (0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "    (2, \"Masters\", \"EECS\", \"UC Berkeley\"),\n",
    "    (1, \"Ph.D\", \"EECS\", \"UC Berkeley\")\n",
    "]).toDF(\"id\", \"degree\", \"department\", \"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkStatus = spark.createDataFrame([\n",
    "    (500, \"Vice president\"), \n",
    "    (250, \"Member\"),\n",
    "    (100, \"Contributor\")\n",
    "]).toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.createOrReplaceTempView(\"person\")\n",
    "graduateProgram.createOrReplaceTempView(\"graduateProgram\")\n",
    "sparkStatus.createOrReplaceTempView(\"sparkStatus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Join\n",
    "* Keep rows with keys that exist in the left and right datasets\n",
    "* Evaluate key in both dataframe or tables and incluse only the rows that evaluate to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(graduate_program = id)'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinExpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|  Purvil Dave|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|Bhavika Joshi|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  2|   Japan Dave|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpression, \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|  Purvil Dave|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|Bhavika Joshi|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  2|   Japan Dave|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM person\n",
    "    INNER JOIN graduateProgram\n",
    "    ON person.graduate_program = graduateProgram.id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Join\n",
    "* Keep rows with keys in either the left or right datasets.\n",
    "* Evaluates keys in both dataframes or tables and include the rows that eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|  Purvil Dave|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   1|Bhavika Joshi|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|   2|   Japan Dave|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|null|         null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpression, \"outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|  Purvil Dave|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   1|Bhavika Joshi|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|   2|   Japan Dave|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|null|         null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM person\n",
    "    FULL OUTER JOIN graduateProgram\n",
    "    ON graduate_program = graduateProgram.id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Outer Join\n",
    "* Keep rows with keys in the left dataset\n",
    "* Left outer joins evaluate the keys in both of the DataFrames or tables and includes all rows from the left DataFrame as well as any rows in the right DataFrame that have a match in the left DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "| id| degree|          department|     school|  id|         name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|   0|  Purvil Dave|               0|          [100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|   1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|   2|   Japan Dave|               1|     [250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|null|         null|            null|           null|\n",
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpression,\"left_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "| id| degree|          department|     school|  id|         name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|   0|  Purvil Dave|               0|          [100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|   1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|   2|   Japan Dave|               1|     [250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|null|         null|            null|           null|\n",
      "+---+-------+--------------------+-----------+----+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM graduateProgram\n",
    "    LEFT OUTER JOIN person\n",
    "    ON graduate_program = graduateProgram.id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Outer join\n",
    "* Keep rows with keys in the right dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|  Purvil Dave|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   1|Bhavika Joshi|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|   2|   Japan Dave|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|null|         null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpression, \"right_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, graduate_program: bigint, spark_status: array<bigint>, id: bigint, degree: string, department: string, school: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM person\n",
    "    RIGHT OUTER JOIN graduateProgram\n",
    "    ON person.graduate_program = graduateProgram.id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Semi Join\n",
    "* Keep the rows in the left and only the left, dataset where key appears in the right dataset\n",
    "* They do not actually include any values from the right DataFrame. They only compare values to see if the value exists in the second DataFrame. If the value does exist, those rows will be kept in the result, even if there are duplicate keys in the left DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpression, \"left_semi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM graduateProgram \n",
    "LEFT SEMI JOIN person\n",
    "ON graduateProgram.id = person.graduate_program\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left anti join\n",
    "* Keep the rows in the left and only the left, dataset where they do not appear in the right dataset.\n",
    "* Opposite of Left semi join.\n",
    "* Use right frame, to compare the key and include the data of left frame wherw key does not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-----------+\n",
      "| id| degree|department|     school|\n",
      "+---+-------+----------+-----------+\n",
      "|  2|Masters|      EECS|UC Berkeley|\n",
      "+---+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpression, \"left_anti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-----------+\n",
      "| id| degree|department|     school|\n",
      "+---+-------+----------+-----------+\n",
      "|  2|Masters|      EECS|UC Berkeley|\n",
      "+---+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * \n",
    "FROM graduateProgram\n",
    "LEFT ANTI JOIN person\n",
    "ON graduateProgram.id = person.graduate_program\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Join\n",
    "* Perform join by implicitly matching the columns between two datasets with the same name.\n",
    "* Make an implicit guess at the column on which you like to join. It finds matching columns and return the result. LEFT, RIGHT and OUTER natural join are supported.\n",
    "* Dangerous when two dataframe has column with same name but the meaning underlying data is different.\n",
    "\n",
    "```\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM graduateProgram NATURAL JOIN person\n",
    "\"\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Join (Cartesian Join)\n",
    "* Match every row in the left dataset with every row in the right.\n",
    "* No condition.\n",
    "* n row and m rows, total will be n * m rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "| id| degree|          department|     school| id|         name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  0|  Purvil Dave|               0|          [100]|\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  2|   Japan Dave|               1|     [250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|  0|  Purvil Dave|               0|          [100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|  2|   Japan Dave|               1|     [250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|  0|  Purvil Dave|               0|          [100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|  2|   Japan Dave|               1|     [250, 100]|\n",
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.crossJoin(person).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "| id| degree|          department|     school| id|         name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  0|  Purvil Dave|               0|          [100]|\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  2|   Japan Dave|               1|     [250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|  0|  Purvil Dave|               0|          [100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|  2|   Japan Dave|               1|     [250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|  0|  Purvil Dave|               0|          [100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|  2|   Japan Dave|               1|     [250, 100]|\n",
      "+---+-------+--------------------+-----------+---+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM graduateProgram CROSS JOIN person\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To enable cross join in session `spark.sql.crossJoin.enable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any expression is valid join operation, as long as it returns boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "|personId|         name|graduate_program|   spark_status| id|        status|\n",
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "|       0|  Purvil Dave|               0|          [100]|100|   Contributor|\n",
      "|       1|Bhavika Joshi|               1|[500, 250, 100]|500|Vice president|\n",
      "|       1|Bhavika Joshi|               1|[500, 250, 100]|250|        Member|\n",
      "|       1|Bhavika Joshi|               1|[500, 250, 100]|100|   Contributor|\n",
      "|       2|   Japan Dave|               1|     [250, 100]|250|        Member|\n",
      "|       2|   Japan Dave|               1|     [250, 100]|100|   Contributor|\n",
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.withColumnRenamed(\"id\", \"personId\").join(sparkStatus, expr(\"array_contains(spark_status, id)\"),\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "|personId|         name|graduate_program|   spark_status| id|        status|\n",
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "|       0|  Purvil Dave|               0|          [100]|100|   Contributor|\n",
      "|       1|Bhavika Joshi|               1|[500, 250, 100]|500|Vice president|\n",
      "|       1|Bhavika Joshi|               1|[500, 250, 100]|250|        Member|\n",
      "|       1|Bhavika Joshi|               1|[500, 250, 100]|100|   Contributor|\n",
      "|       2|   Japan Dave|               1|     [250, 100]|250|        Member|\n",
      "|       2|   Japan Dave|               1|     [250, 100]|100|   Contributor|\n",
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM\n",
    "(SELECT id as personId, name, graduate_program, spark_status \n",
    "FROM person)\n",
    "INNER JOIN sparkStatus\n",
    "ON array_contains(spark_status, id)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicate Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different join expression\n",
    "    - Change join expression from boolean to string will removes one of the columns for you during the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradProgramDupe = graduateProgram.withColumnRenamed(\"id\", \"graduate_program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+--------------------+-----------+\n",
      "|graduate_program| degree|          department|     school|\n",
      "+----------------+-------+--------------------+-----------+\n",
      "|               0|Masters|School of Informa...|UC Berkeley|\n",
      "|               2|Masters|                EECS|UC Berkeley|\n",
      "|               1|   Ph.D|                EECS|UC Berkeley|\n",
      "+----------------+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradProgramDupe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+\n",
      "| id|         name|graduate_program|   spark_status|\n",
      "+---+-------------+----------------+---------------+\n",
      "|  0|  Purvil Dave|               0|          [100]|\n",
      "|  1|Bhavika Joshi|               1|[500, 250, 100]|\n",
      "|  2|   Japan Dave|               1|     [250, 100]|\n",
      "+---+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+-------------+---------------+-------+--------------------+-----------+\n",
      "|graduate_program| id|         name|   spark_status| degree|          department|     school|\n",
      "+----------------+---+-------------+---------------+-------+--------------------+-----------+\n",
      "|               0|  0|  Purvil Dave|          [100]|Masters|School of Informa...|UC Berkeley|\n",
      "|               1|  1|Bhavika Joshi|[500, 250, 100]|   Ph.D|                EECS|UC Berkeley|\n",
      "|               1|  2|   Japan Dave|     [250, 100]|   Ph.D|                EECS|UC Berkeley|\n",
      "+----------------+---+-------------+---------------+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(gradProgramDupe, \"graduate_program\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+----------------+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status|graduate_program| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+----------------+-------+--------------------+-----------+\n",
      "|  0|  Purvil Dave|               0|          [100]|               0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|Bhavika Joshi|               1|[500, 250, 100]|               1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  2|   Japan Dave|               1|     [250, 100]|               1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+----------------+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(gradProgramDupe, person[\"graduate_program\"] == gradProgramDupe[\"graduate_program\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drop column after join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---------------+----------------+-------+--------------------+-----------+\n",
      "| id|         name|   spark_status|graduate_program| degree|          department|     school|\n",
      "+---+-------------+---------------+----------------+-------+--------------------+-----------+\n",
      "|  0|  Purvil Dave|          [100]|               0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|Bhavika Joshi|[500, 250, 100]|               1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  2|   Japan Dave|     [250, 100]|               1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------------+---------------+----------------+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(gradProgramDupe, person[\"graduate_program\"] == gradProgramDupe[\"graduate_program\"]).drop(person[\"graduate_program\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rename ecolumn before join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Spark performs join?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spark do cluster communication\n",
    "    - Shuffle join, all to all communication, \n",
    "    - broadcast join\n",
    "* In spark we have big table and small table\n",
    "* Big table to big table\n",
    "    - Shuffle join takes place, every node will talk to other node, they share data according to which node has certain keys. Expensive joins because network has lots of traffic if data is not partitioned well.\n",
    "    ![](images/big_to_big.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Big table to small table\n",
    "    - When table is small enough to fit in memory of single worker node, We can use broadcast join.\n",
    "    - Replicate small dataframe to all worker node in beginning. So here we do all overhead at beginning so, individual worker node can work without waiting or communicating with other worker node.\n",
    "    ![](images/broadcast_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) SortMergeJoin [graduate_program#10L], [id#24L], Inner\n",
      ":- *(2) Sort [graduate_program#10L ASC NULLS FIRST], false, 0\n",
      ":  +- Exchange hashpartitioning(graduate_program#10L, 200)\n",
      ":     +- *(1) Project [_1#0L AS id#8L, _2#1 AS name#9, _3#2L AS graduate_program#10L, _4#3 AS spark_status#11]\n",
      ":        +- *(1) Filter isnotnull(_3#2L)\n",
      ":           +- Scan ExistingRDD[_1#0L,_2#1,_3#2L,_4#3]\n",
      "+- *(4) Sort [id#24L ASC NULLS FIRST], false, 0\n",
      "   +- Exchange hashpartitioning(id#24L, 200)\n",
      "      +- *(3) Project [_1#16L AS id#24L, _2#17 AS degree#25, _3#18 AS department#26, _4#19 AS school#27]\n",
      "         +- *(3) Filter isnotnull(_1#16L)\n",
      "            +- Scan ExistingRDD[_1#16L,_2#17,_3#18,_4#19]\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpression).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-d5a4580bd9a8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-d5a4580bd9a8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    * Even we can hint optimizer that we like to perform certain kind of join\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "* Even we can hint optimizer that we like to perform certain kind of join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [graduate_program#10L], [id#24L], Inner, BuildRight\n",
      ":- *(2) Project [_1#0L AS id#8L, _2#1 AS name#9, _3#2L AS graduate_program#10L, _4#3 AS spark_status#11]\n",
      ":  +- *(2) Filter isnotnull(_3#2L)\n",
      ":     +- Scan ExistingRDD[_1#0L,_2#1,_3#2L,_4#3]\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]))\n",
      "   +- *(1) Project [_1#16L AS id#24L, _2#17 AS degree#25, _3#18 AS department#26, _4#19 AS school#27]\n",
      "      +- *(1) Filter isnotnull(_1#16L)\n",
      "         +- Scan ExistingRDD[_1#16L,_2#17,_3#18,_4#19]\n"
     ]
    }
   ],
   "source": [
    "person.join(broadcast(graduateProgram), joinExpression).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
